{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Reading data and creating a recomender Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Read the CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique users : 368104 ,and Unique apps: 11045\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AMNRMCC3IHXSD</td>\n",
       "      <td>B004AGCR1K</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A249RKULWQDFA0</td>\n",
       "      <td>B004AGCR1K</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A21BZ7ERKIVFFB</td>\n",
       "      <td>B004AGCR1K</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A5L95BPFYPCPN</td>\n",
       "      <td>B004ALJIOE</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A2KM7J2DNEG61C</td>\n",
       "      <td>B004ALJIOE</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             user        item  rating\n",
       "0   AMNRMCC3IHXSD  B004AGCR1K     1.0\n",
       "1  A249RKULWQDFA0  B004AGCR1K     1.0\n",
       "2  A21BZ7ERKIVFFB  B004AGCR1K     1.0\n",
       "3   A5L95BPFYPCPN  B004ALJIOE     5.0\n",
       "4  A2KM7J2DNEG61C  B004ALJIOE     5.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "df = pd.read_csv('ratings_Apps_for_Android_processed.csv')\n",
    "# df.columns = ['user','item','rating']\n",
    "\n",
    "num_items = df.item.nunique()\n",
    "num_users = df.user.nunique()    \n",
    "print(\"Unique users : {} ,and Unique apps: {}\".format(num_users, num_items))   \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Normalising the reviews from 0-5 to 0-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "r = df['rating'].values.astype(float)\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(r.reshape(-1,1))\n",
    "df_normalized = pd.DataFrame(x_scaled)\n",
    "df['rating'] = df_normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 Converting the dataframe to a matrix.\n",
    "with users as rows and the different apps as columns and values as ratings.\n",
    "Fill all non available ratings as zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "small_db = True\n",
    "if small_db:\n",
    "    _u = list(df.user.unique())\n",
    "    df = df.loc[df['user'].isin(_u[0:10000])]\n",
    "    matrix = df.pivot(index='user', columns='item', values='rating')\n",
    "    matrix.fillna(0, inplace=True)\n",
    "    users = matrix.index.tolist()\n",
    "    items = matrix.columns.tolist()\n",
    "    matrix = matrix.values\n",
    "else:\n",
    "    print('Takes more than 20 Mins!!!')\n",
    "    items = list(df.item.unique())\n",
    "    users = list(df.user.unique())\n",
    "    matrix = np.zeros([num_users,num_items])\n",
    "    for i in tqdm(range(0,df.shape[0])):\n",
    "        _t = df.loc[i]\n",
    "        matrix[users.index(_t['user']),items.index(_t['item'])]  = _t['rating']\n",
    "num_items = df.item.nunique()\n",
    "num_users = df.user.nunique() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Building a tensorflow model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Buidling a tensorflow model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "num_input = num_items\n",
    "num_hidden_1 = 30\n",
    "num_hidden_2 = 10\n",
    "\n",
    "EXPORT_DIR = './model'\n",
    "\n",
    "if os.path.exists(EXPORT_DIR):\n",
    "    shutil.rmtree(EXPORT_DIR)\n",
    "    \n",
    "X = tf.placeholder(tf.float32, [None, num_input],name='input_tensor')\n",
    "weights = {\n",
    "    'encoder_h1': tf.Variable(tf.random_normal([num_input, num_hidden_1], dtype=tf.float32), name='encoder_h1'),\n",
    "    'encoder_h2': tf.Variable(tf.random_normal([num_hidden_1, num_hidden_2], dtype=tf.float32),name='encoder_h2'),\n",
    "    'decoder_h1': tf.Variable(tf.random_normal([num_hidden_2, num_hidden_1], dtype=tf.float32),name='decoder_h1'),\n",
    "    'decoder_h2': tf.Variable(tf.random_normal([num_hidden_1, num_input], dtype=tf.float32),name='decoder_h2'),\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'encoder_b1': tf.Variable(tf.random_normal([num_hidden_1], dtype=tf.float32),name='encoder_b1'),\n",
    "    'encoder_b2': tf.Variable(tf.random_normal([num_hidden_2], dtype=tf.float32),name='encoder_b2'),\n",
    "    'decoder_b1': tf.Variable(tf.random_normal([num_hidden_1], dtype=tf.float32),name='decoder_b1'),\n",
    "    'decoder_b2': tf.Variable(tf.random_normal([num_input], dtype=tf.float32),name='decoder_b2'),\n",
    "}\n",
    "\n",
    "# Building the encoder\n",
    "def encoder(x):\n",
    "    # Encoder Hidden layer with sigmoid activation #1\n",
    "    layer_1 = tf.nn.sigmoid(tf.add(tf.matmul(x, weights['encoder_h1']), biases['encoder_b1']),name='encoder_layer1')\n",
    "    # Encoder Hidden layer with sigmoid activation #2\n",
    "    layer_2 = tf.nn.sigmoid(tf.add(tf.matmul(layer_1, weights['encoder_h2']), biases['encoder_b2']),name='encoder_layer2')\n",
    "    return layer_2\n",
    "\n",
    "# Building the decoder\n",
    "def decoder(x):\n",
    "    # Decoder Hidden layer with sigmoid activation #1\n",
    "    layer_1 = tf.nn.sigmoid(tf.add(tf.matmul(x, weights['decoder_h1']), biases['decoder_b1']),name='decoder_layer1')\n",
    "    # Decoder Hidden layer with sigmoid activation #2\n",
    "    layer_2 = tf.nn.sigmoid(tf.add(tf.matmul(layer_1, weights['decoder_h2']), biases['decoder_b2']),name='decoder_layer2')\n",
    "    return layer_2\n",
    "\n",
    "\n",
    "# Construct model\n",
    "encoder_op = encoder(X)\n",
    "decoder_op = decoder(encoder_op)\n",
    "\n",
    "\n",
    "# Prediction\n",
    "y_pred = decoder_op\n",
    "\n",
    "\n",
    "# Targets are the input data.\n",
    "y_true = X\n",
    "\n",
    "# Define loss and optimizer, minimize the squared error\n",
    "\n",
    "loss = tf.losses.mean_squared_error(y_true, y_pred)\n",
    "optimizer = tf.train.RMSPropOptimizer(0.03).minimize(loss)\n",
    "\n",
    "# Define evaluation metrics\n",
    "\n",
    "eval_x = tf.placeholder(tf.int32, )\n",
    "eval_y = tf.placeholder(tf.int32, )\n",
    "pre, pre_op = tf.metrics.precision(labels=eval_x, predictions=eval_y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Train the model and save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Loss: 0.3990599581828484\n",
      "Epoch: 2 Loss: 0.3960302479756184\n",
      "Epoch: 3 Loss: 0.37613681187996495\n",
      "Epoch: 4 Loss: 0.2938448270926109\n",
      "Epoch: 5 Loss: 0.1187096135929609\n",
      "Epoch: 6 Loss: 0.03362015357766396\n",
      "Epoch: 7 Loss: 0.01737565131714711\n",
      "Epoch: 8 Loss: 0.014089030715135427\n",
      "Epoch: 9 Loss: 0.010965578090877105\n",
      "Epoch: 10 Loss: 0.009747261921755778\n",
      "Epoch: 11 Loss: 0.008894290321339399\n",
      "Epoch: 12 Loss: 0.008364836804759808\n",
      "Epoch: 13 Loss: 0.00834521030386289\n",
      "Epoch: 14 Loss: 0.007562704933568453\n",
      "Epoch: 15 Loss: 0.0068592444324913696\n",
      "Epoch: 16 Loss: 0.006075209233527765\n",
      "Epoch: 17 Loss: 0.005717557986290791\n",
      "Epoch: 18 Loss: 0.0053570067080167625\n",
      "Epoch: 19 Loss: 0.005111882152656714\n",
      "Epoch: 20 Loss: 0.005106533065629311\n",
      "Epoch: 21 Loss: 0.005101367413329008\n",
      "Epoch: 22 Loss: 0.0050962816279094955\n",
      "Epoch: 23 Loss: 0.005089629548960007\n",
      "Epoch: 24 Loss: 0.00483060669965851\n",
      "Epoch: 25 Loss: 0.004618493255036764\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "# local_init = tf.local_variables_initializer()\n",
    "epochs = 25\n",
    "batch_size = 256\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    num_batches = int(matrix.shape[0] / batch_size)\n",
    "    matrix = np.array_split(matrix, num_batches)\n",
    "\n",
    "    for i in range(epochs):\n",
    "\n",
    "        avg_cost = 0\n",
    "\n",
    "        for batch in matrix:\n",
    "            _, l = sess.run([optimizer, loss], feed_dict={X: batch})\n",
    "            avg_cost += l\n",
    "\n",
    "        avg_cost /= num_batches\n",
    "\n",
    "        print(\"Epoch: {} Loss: {}\".format(i + 1, avg_cost))\n",
    "        \n",
    "    WC1 = weights['encoder_h1'].eval(sess)\n",
    "    BC1 = biases['encoder_b1'].eval(sess)\n",
    "    WC2 = weights['encoder_h2'].eval(sess)\n",
    "    BC2 = biases['encoder_b2'].eval(sess)\n",
    "    WD1 = weights['decoder_h1'].eval(sess)\n",
    "    BD1 = biases['decoder_b1'].eval(sess)\n",
    "    WD2 = weights['decoder_h2'].eval(sess)\n",
    "    BD2 = biases['decoder_b2'].eval(sess)\n",
    "    saver = tf.train.Saver()\n",
    "    save_path = saver.save(sess, \"./Seekers_Model\")\n",
    "matrix = np.concatenate(matrix, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 Predicting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction\n",
      "[[0.6973344  0.03454772 0.9281022  ... 0.05060022 0.98643965 0.02912048]]\n",
      "[[0.06257072 0.5338691  0.23451154 ... 0.0204625  0.05798892 0.00115483]]\n"
     ]
    }
   ],
   "source": [
    "print('Prediction')\n",
    "def make_singlePred(sample):\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "        preds = sess.run(decoder_op, feed_dict={X: samples})\n",
    "\n",
    "        return preds\n",
    "samples = np.zeros([1,num_input])\n",
    "\n",
    "\n",
    "print(make_singlePred(samples))\n",
    "    \n",
    "samples = np.zeros([1,num_input])\n",
    "samples[0,num_input-1]=0.6\n",
    "# the user gave num_input-1 app a rating of 0.6*5=3 star\n",
    "print(make_singlePred(samples))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4 Freeze model for android development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./Seekers_Model\n",
      "INFO:tensorflow:Froze 8 variables.\n",
      "INFO:tensorflow:Converted 8 variables to const ops.\n"
     ]
    }
   ],
   "source": [
    "def freeze_graph(model_dir, output_node_names):\n",
    "    checkpoint = tf.train.get_checkpoint_state(model_dir)\n",
    "    input_checkpoint = checkpoint.model_checkpoint_path\n",
    "    absolute_model_dir = \"/\".join(input_checkpoint.split('/')[:-1])\n",
    "    output_graph = absolute_model_dir + \"/frozen_model.pb\"\n",
    "    clear_devices = True\n",
    "    with tf.Session(graph=tf.Graph()) as sess:\n",
    "        saver = tf.train.import_meta_graph(input_checkpoint + '.meta', clear_devices=clear_devices)\n",
    "        saver.restore(sess, input_checkpoint)\n",
    "        output_graph_def = tf.graph_util.convert_variables_to_constants(\n",
    "            sess,tf.get_default_graph().as_graph_def(),output_node_names.split(\",\")) \n",
    "        with tf.gfile.GFile(output_graph, \"wb\") as f:\n",
    "            f.write(output_graph_def.SerializeToString())\n",
    "    return output_graph_def\n",
    "\n",
    "_ = freeze_graph('.', 'decoder_layer2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.5 Convert the model from tensorflow to tflite using toco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below Please replace --input_shape=1,#### with --input_shape=1,11045\n"
     ]
    }
   ],
   "source": [
    "print('Below Please replace --input_shape=1,#### with --input_shape=1,{}'.format(num_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-11-18 04:47:22.084158: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n"
     ]
    }
   ],
   "source": [
    "!toco --graph_def_file=frozen_model.pb --output_file=optimized_graph.lite   --input_format=TENSORFLOW_GRAPHDEF   --output_format=TFLITE   --input_shape=1,11045 --input_array=\"input_tensor\" --output_array=\"decoder_layer2\" --input_data_type=FLOAT --inference_type=FLOAT"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
